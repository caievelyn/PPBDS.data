# Priorities

## Thomas

* pkgdown

  - Start using package numbering correctly

  - Add NEWS file, using recommended practices from R Packages.

  - Make look more like Healy, especially sidebar.

* Called `nominate`. DW NOMINATE from VoteView project: https://www.voteview.com/data.

* Investigate "found 2 marked UTF-8 strings"


* pkgdown

  - Look nice themes or yaml option

  - Discuss logo. Ullyseus and the Sirens, with url

  - Nicer graphics on home page.


## Miro

* Clean up `nes`.

* Called `nhanes`. Pick out some interesting variables from the NHANES data which lives in the NHANES package. That is, make_nhanes.R script will start with library(NHANES), meaning that it will assume that the package has already been installed.

* Called `kenya`. Use Electoral Administration in Fledgling Democracies: Experimental Evidence from Kenya at https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/UT25HQ. This is another good international paper. We can use Erin's code: https://github.com/eguetzloe/kenya-electoral-administration.

* Clean up `sps`. Which variables do we need? What do they show? What should they be called?


## Other

* Add inst/papers with all the relevant papers, then link there from the help pages.

* Figure out this note from checking the package: "Note: found 2 marked UTF-8 strings"

* Figure out proper numbering for releases.



## Overview

We are creating an R package, PPBDS.data, which will contain a collection of interesting tibbles, with a focus on political science and designed for classroom use. Their main use will be for Gov 50 and for the Preceptor's Primer. Each tibble will have a small number of variables, about as many as will fit across the screen when the tibble is printed. (Tibbles need to be simple since we don't want to overwhelm readers. The focus should be on the code and the models, not on the data.) See below for instructions on installing git-lfs. We might have one very "wide" tibble, just to have an example to work with when we want to try a model with lots of variables.

### Instructions

* Write scripts which create our data sets and adds them to our PPBDS.data package. Write associated help files. Skim [*R Packages*](https://r-pkgs.org/), but read closely the [data section](https://r-pkgs.org/data.html). Examine [covdata package](https://kjhealy.github.io/covdata/). Use **usethis** and **pkgdown** packages.

* Follow the conventions with the trains data: make_trains.R (in data-raw/), trains.rda (in data/), trains.R (in R/). Note that the name of the tibble -- "trains" -- appears in the file name of each of the three key things you are creating.

* Main workflow is that raw data is placed in the data-raw/ directory. It is read and cleaned in the make_name-of-tibble.R script, the last step of which is to create the name-of-tibble.rda file, using `usethis::use_data(name-of-tibble, overwrite = TRUE)`. The make_name-of-tibble.R has lots and lots of documentation, including the details of where the original data came from, and instructions on how to download it, if necessary. (At some point, we might turn this into a function, as Healy does, but not right now.) name-of-tibble.R provides the information for R to create the help file. It includes at least two paragraphs of background on the data source itself, ideally to include a key academic paper.

* Think hard about variable type. Don't make something a factor unless you have a reason to. If something has a natural order, then perhaps it should be an ordered factor. Document your reasoning in your make_name-of-tibble.R script. Examine the choices made in make_trains.R.


### pkgdown

* We are currently using pkgdown to make our website. But it is confusing and a bit fragile. Nor have I done a good job of documenting my lessons. Start [here](https://pkgdown.r-lib.org/articles/pkgdown.html). I had to run `usethis::use_pkgdown()` once, and then do some fussing to get the automated push stuff to work. Even though I only did this a few weeks ago, I have already forgotten the key steps. Weak! Document better!

* You need to use `pkgdown::build_site()` to create the site after you have made some changes.

* Need to make the home page nicer. Follow [these instructions](https://pkgdown.r-lib.org/reference/build_home.html).


### git-lfs

Previously, we used git-lfs. See below for instructions. But, this led to Githib charging us too much money! So, we no longer need it, since we removed the anes_timeseries_cdf.dta from the repo.

Note that you need to have git-lfs installed to work with our repo because we use some big data sets. See [here](https://git-lfs.github.com/) for instructions. Note that the current Mac OS (Catalina) will give you a bit of a problem. To solve it, I did:

brew install git-lfs
xattr -d com.apple.quarantine /usr/local/bin/git-lfs

The first command is just a standard way of installing things on the Mac. The second step was necessary because Apple has tighted the safety checks on downloaded programs. At some point, only the first step will be necessary. But, for now, you need to do the second to confirm to Apple that git-lfs is safe.

Once you have done this, all your standard git commands will work as usual. Note that data-raw/ in in .Rbuildignore, so that directory is not included in the distributed package. That is cool since we don't want the package to force people to download hundreds of megs of raw data.


### Data Sets


* I love this discussion: https://statmodeling.stat.columbia.edu/2020/07/02/no-i-dont-believe-that-claim-based-on-regression-discontinuity-analysis-that/. Data for the paper is here: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/IBKYRX&widget=dataverse@harvard

* Science experiment: https://science.sciencemag.org/content/358/6364/776/tab-figures-data

* Need something from Matt Blackwell's work on slavery. Ultimate use may just be in making an example for the maps appendix, which should be longer.

* Called `congress`. Something about the results of US congressional elections over several election cycles. 538? Really want this to include some measure of campaign spending so we can discuss a (potential) causal effect. Didn't they have a model which they used for the 2018 election? If they estimated a model, they must have some data.

* Called `police`. [Open police data](https://openpolicing.stanford.edu/data/). Something with millions of rows and, ideally, geographic coordinates. We won't include this data in our repo. Instead, the make_police.R script will download and process it. Ideally, we can get the final police.rda to be less than 100 meg so that we don't need to turn on git-lfs again.

* Maybe [GSS](http://gss.norc.org/). Isn't there already an R package? https://kjhealy.github.io/gssr/. Could issue a PR for changing the installation instructions to use remotes:: instead of devtools.

* FEC data. This is complex and important enough that it might become a stand-alone package. See [DIME](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/O5PX0B&version=2.2).

* Shiro: I also have a clean large dataset of satellite lights in Africa from this period using this paper: https://www.aeaweb.org/articles?id=10.1257/aer.20161385

* Called `deaths`. Maybe that demography data we used on the last day of 1005 this semester? Or is that too big?
